{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bitzyypytorch13detectron2conda1c0c5856074d413db80dd59f664bc4df",
   "display_name": "Python 3.7.7 64-bit ('zyy_pytorch1.3_detectron2': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "opj = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle jester train/val set\n",
    "# get new train/val split\n",
    "JESTER_BASE_PATH = \"/ssd4/zhangyiyang/data/jester-v1\"\n",
    "val_num = 20000\n",
    "\n",
    "t = open(opj(JESTER_BASE_PATH, \"train_videofolder.txt\"), \"r\")\n",
    "v = open(opj(JESTER_BASE_PATH, \"val_videofolder.txt\"), \"r\")\n",
    "total_f = open(opj(JESTER_BASE_PATH, \"total_videofolder.txt\"), \"w\")\n",
    "total_f.writelines(t.readlines())\n",
    "total_f.write(\"\\n\")\n",
    "total_f.writelines(v.readlines())\n",
    "total_f.write(\"\\n\")\n",
    "total_f.close()\n",
    "t.close()\n",
    "v.close()\n",
    "\n",
    "t = open(opj(JESTER_BASE_PATH, \"new_train_videofolder.txt\"), \"w\")\n",
    "v = open(opj(JESTER_BASE_PATH, \"new_val_videofolder.txt\"), \"w\")\n",
    "total_f = open(opj(JESTER_BASE_PATH, \"new_total_videofolder.txt\"), \"r\")\n",
    "lines = total_f.readlines()\n",
    "lines = np.array(lines)\n",
    "np.random.shuffle(lines)\n",
    "t.writelines(lines[:-val_num])\n",
    "v.writelines(lines[-val_num:])\n",
    "total_f.close()\n",
    "t.close()\n",
    "v.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split total samples, to train/val\n",
    "val_percent = 0.1\n",
    "\n",
    "# read total samples\n",
    "with open(\"/ssd4/zhangyiyang/data/AR/total_samples.txt\", \"r\") as f:\n",
    "    total_samples = f.readlines()\n",
    "total_samples = [l.strip() for l in total_samples]\n",
    "\n",
    "# sort samples by label\n",
    "sample_cnt = {}\n",
    "for idx, sample in enumerate(total_samples):\n",
    "    splits = sample.split(\" \")\n",
    "    if sample_cnt.get(splits[-1]) is None:\n",
    "        sample_cnt[splits[-1]] = [sample]\n",
    "    else:\n",
    "        sample_cnt[splits[-1]].append(sample)\n",
    "\n",
    "# split train/val\n",
    "train_list = []\n",
    "val_list = []\n",
    "for key in sample_cnt.keys():\n",
    "    val_cnt = int(val_percent * len(sample_cnt[key]))\n",
    "    train_list += sample_cnt[key][:-val_cnt]\n",
    "    val_list += sample_cnt[key][-val_cnt:]\n",
    "\n",
    "# shuffle train list\n",
    "np.random.shuffle(train_list)\n",
    "\n",
    "# create train/val txt\n",
    "val_file = open(\"/ssd4/zhangyiyang/data/AR/val_samples.txt\", \"w\")\n",
    "train_file = open(\"/ssd4/zhangyiyang/data/AR/train_samples.txt\", \"w\")\n",
    "val_file.write(\"\\n\".join(val_list))\n",
    "train_file.write(\"\\n\".join(train_list))\n",
    "val_file.close()\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}